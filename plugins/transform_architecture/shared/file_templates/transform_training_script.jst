require('torch')
require('nn')
require('nngraph')
require('rnn')
require('optim')
require('mime')
require('image')
local _ = require('underscore')
cjson = require('cjson')
local JSON = require('./JSON')
require('./EBDebug')
require('./EBWrapDebug')
require('./EBWrapTable')
require('{{=it.rootModuleName}}')
require('{{=it.rootCriterionName}}')
local sqlite3 = require("lsqlite3")

-- Define our object, TransformTrainingScript.
-- Do not change the name of this class!
local TransformTrainingScript = {}
TransformTrainingScript.__index = TransformTrainingScript


-- Creates the TransformTrainingScript object.
-- Do not change the name of this class
function TransformTrainingScript.new()
    local self = {}

    setmetatable(self, TransformTrainingScript)

    -- Connect to the other nodes in the process
    self.ipctree = require 'ipc.LocalhostTree'(tonumber(arg[1]), tonumber(arg[2]))
    self.allReduceSGD = require 'distlearn.AllReduceSGD'(self.ipctree)

    -- Try and setup the GPU
    local ok, cunn = pcall(require, 'cunn')
    local ok2, cutorch = pcall(require, 'cutorch')
    if ok and ok2 then
        self.gpuEnabled = true
        cutorch.setDevice(1)
    else
        self.gpuEnabled = false
    end

    -- generate SVG of the graph with the problem node highlighted
    -- and hover over the nodes in svg to see the filename:line_number info
    -- nodes will be annotated with local variable names even if debug mode is not enabled.
    nngraph.setDebug(true)

    -- Increase the stack limit
    --print(coroutine)
    --local olddefault = coroutine.cstacksize({{=(1024 * 1024 * 256)}})

    -- Initialization optimization state
    self.optimizationAlgorithm = 'adamax'
    self.optimState = {}

    -- Is the module initialized
    self.moduleInitialized = false

    return self
end

function TransformTrainingScript:createModule()
    -- Create the main neural network module
    self.module = nn.{{=it.rootModuleName}}(self)
    if self.gpuEnabled then
        self.module:cuda()
    end

    -- Create a copy of the main neural network module that will be used for saving
    self.moduleSaveCopy = nn.{{=it.rootModuleName}}(self)

    -- Create the main criterion for training
    self.criterion = nn.{{=it.rootCriterionName}}(self)
    if self.gpuEnabled then
        self.criterion:cuda()
    end
    self.criterionClones = {}

    -- Prepare the parameters
    self.params, self.gradParams = self.module:getParameters()

    -- Set the module as initialized
    self.moduleInitialized = true
end

function TransformTrainingScript:localize(obj)
    if self.gpuEnabled then
        return obj:cuda()
    else
        return obj
    end
end


function TransformTrainingScript:getCriterion(index)
   local criterion = self.criterionClones[index]
   if not criterion then
      criterion = self.criterion:clone()
      self.criterionClones[index] = criterion
   end
   return criterion
end

function TransformTrainingScript:evaluateTrainingIteration(inputBatch, outputBatch)
    local batchOutputs
    local outputs

    {{= it.generateLocalizeFunction(it.inputSchema, "localizeInputRoot").replace(/\n/g, "\n    ") }}
    {{= it.generateLocalizeFunction(it.outputSchema, "localizeOutputRoot").replace(/\n/g, "\n    ") }}

    if self.gpuEnabled then
        inputBatch = localizeInputRoot(inputBatch)
        for n=1,#outputBatch do
            outputBatch[n] = localizeOutputRoot(outputBatch[n])
        end
    end

    local iteration = function(params)
        --if params_ ~= self.params then
        --    self.params:copy(params_)
        --end
        self.gradParams:zero()

        local expectedOutputs = {}
        local loss = 0

        ------------------- forward pass -------------------
        self.module:training()

        batchOutputs = self.module:forward(inputBatch)
        outputs = self:unwindBatchOutput(batchOutputs)

        ------------------- criterion ----------------------
        -- Separately run each item in the batch through criterion
        local derivatives = {}
        for n=1,#outputs do
            local criterion = self:getCriterion(n)
            loss = loss + criterion:forward(outputs[n], outputBatch[n])
            local criterionDerivatives = criterion:backward(outputs[n], outputBatch[n])
            table.insert(derivatives, criterionDerivatives)
        end

        ------------------- backward pass -------------------
        local derivativesBatch = self:prepareDerivatives(derivatives)

        if self.gpuEnabled then
            derivativesBatch = localizeOutputRoot(derivativesBatch)
        end

        local inputDerivatives = self.module:backward(inputBatch, derivativesBatch)

        -- clip gradient element-wise
        self.gradParams:clamp(-5, 5)

        -- Gather the grads from all nodes
        self.allReduceSGD.sumAndNormalizeGradients({self.gradParams})

        return loss, self.gradParams
    end

    local _ignore, loss
    _ignore, loss = optim[self.optimizationAlgorithm](iteration, self.params, self.optimState)

    -- Collect gabarge at the end of each iteration - prevents build up of useless memory
    collectgarbage()

    return {
        loss = loss[1],
        output = outputs
    }
end


function TransformTrainingScript:evaluateBatch(inputBatch)
    ------------------- forward pass -------------------
    self.module:evaluate()

    {{= it.generateLocalizeFunction(it.inputSchema, "localizeInputRoot") }}

    if self.gpuEnabled then
        inputBatch = localizeInputRoot(inputBatch)
    end

    local batchOutputs = self.module:forward(inputBatch)
    return self:unwindBatchOutput(batchOutputs)
end

-- Prepares an input batch
function TransformTrainingScript:prepareInputBatch(samples)
    {{= it.prepareBatch(it.inputSchema, "prepareInputRoot").replace(/\n/g, "\n    ") }}

    local converted = {}
    for n=1,#samples do
        converted[n] = self:convertInputIn(samples[n])
    end

    return prepareInputRoot(converted)
end

-- Prepares an output batch
function TransformTrainingScript:prepareOutputBatch(samples)
    local converted = {}
    for n=1,#samples do
        converted[n] = self:convertOutputIn(samples[n])
    end

    return converted
end


-- Prepares a batch of derivatives back from the criterion
function TransformTrainingScript:prepareDerivatives(derivatives)
    {{= it.prepareBatch(it.outputSchema, "prepareDerivativesRoot").replace(/\n/g, "\n    ") }}
    return prepareDerivativesRoot(derivatives)
end


-- Unwinds a given batch output, separating its outputs composed of the given data points
function TransformTrainingScript:unwindBatchOutput(batch1)
    {{= it.unwindBatchOutput(it.outputSchema, "unwindOutputRoot").replace(/\n/g, "\n    ") }}
    return unwindOutputRoot(batch1)
end


-- This method converts a piece of input data from object format into Torch Tensor format.
function TransformTrainingScript:convertInputIn(data1)
    {{= it.convertDataIn(it.inputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- This method converts a piece of output data from object format into Torch Tensor format.
function TransformTrainingScript:convertOutputIn(data1)
    {{= it.convertDataIn(it.outputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- This method converts a piece of output data from Torch Tensor format back into regular object format
function TransformTrainingScript:convertOutputOut(data1)
    {{= it.convertDataOut(it.outputSchema, "convert").replace(/\n/g, "\n    ") }}
    return convert(data1)
end


-- Return the word vector for a given string
function TransformTrainingScript:getWordVector(word)
    if self.wordVectorDB == nil then
        self.wordVectorDB = assert(sqlite3.open("{{=it.wordVectorDBPath}}"))
        self.wordVectorRequest = assert(self.wordVectorDB:prepare("SELECT tensor FROM word_vectors WHERE word = ?"))
    end

    local outputTensor = torch.zeros(1, 300):double()
    self.wordVectorRequest:bind_values(word)
    local count = 0
    for row in self.wordVectorRequest:nrows() do
        count = count + 1
        outputTensor[1]:copy(torch.deserialize(self.wordVectorRequest:get_value(0)))
    end
    self.wordVectorRequest:reset()

    if count == 0 then
        return nil
    end
    return outputTensor
end


-- This method can be used to send a log message upwards to Electric Brain, which
-- will be visible on the ElectricBrain interface. Useful for debugging.
function TransformTrainingScript:log(message)
    local stackInfo = debug.getinfo(2, 'fSl')
    if stackInfo.func == print then
        stackInfo = debug.getinfo(3, 'fSl')
    end

    local response = {
        type = "log"
    }

    if torch.type(message) == 'string' then
        response.message = message
    else
        response.message = JSON:encode(message, {}, {
           pretty = true,
           indent = "   ",
           align_keys = false,
        })

        if not response.message then
            response.message = tostring(message)
        end
    end

    response.message = stackInfo.source .. ":" .. stackInfo.currentline .. "  " .. response.message

    self:sendResponse(response)
end


-- This method sends a message to the ElectricBrain manager process.
function TransformTrainingScript:sendResponse(response)
    io.write(cjson.encode(response) .. "\n")
    io.flush()
end

-- This is the main loop which communicates with the manager process in Electric Brain code.
-- Its generally best not to change this too much.
function TransformTrainingScript:enterTrainingLoop()
    -- Now start waiting for messages from standard input
    repeat
        local commandString = io.read("*line")
        local command = cjson.decode(commandString)
        if command then
            if command.type == "handshake" then
                -- Send back a handshake response
                self:sendResponse({type = "handshake"})
            elseif command.type == "reset" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- Resets the model with randomly generated parameters
                self.params:uniform(command.initializationRangeBottom, command.initializationRangeTop)
                self.gradParams:zero()

                -- Set the optimization parameters
                self.optimizationAlgorithm = command.optimizationAlgorithm
                self.optimState = command.optimizationParameters

                self:sendResponse({type = "resetCompleted"})
            elseif command.type == "iteration" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The iteration command advances the network with one forward and backward pass.
                -- It must be given the filename of input and output batches that have been prepared in advance
                -- using the "prepareInputBatch" and "prepareOutputBatch"
                local inputBatchFile = torch.load(command.inputBatchFilename)
                local outputBatchFile = torch.load(command.outputBatchFilename)

                local results = self:evaluateTrainingIteration(inputBatchFile.data, outputBatchFile.data)

                local convertedResults = {}
                for n = 1,#results.output do
                    local id = inputBatchFile.ids[n]
                    local result = results.output[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    objects = convertedResults,
                    type = "iterationCompleted",
                    loss = results.loss
                }
                self:sendResponse(response)
            elseif command.type == "prepareInputBatch" then
                -- The prepare batch command assembles a batch and then writes it
                -- out to a file, so that its ready to go for the main training
                -- script
                local batch = {
                    data = self:prepareInputBatch(command.samples),
                    ids = command.ids
                }

                torch.save(command.fileName, batch)

                self:sendResponse({type="batchInputPrepared", fileName=command.fileName})
            elseif command.type == "prepareOutputBatch" then
                -- The prepare batch command assembles a batch and then writes it
                -- out to a file, so that its ready to go for the main training
                -- script
                local batch = {
                    data = self:prepareOutputBatch(command.samples),
                    ids = command.ids
                }

                torch.save(command.fileName, batch)

                self:sendResponse({type="batchOutputPrepared", fileName=command.fileName})
            elseif command.type == "stats" then
                -- The 'stats' command is used to provide statistics up to the surrounding manager
                -- code

                -- Start with garbage collection, so we don't count anything we don't want

                collectgarbage('collect')
                local stats = {
                    memoryUsage = collectgarbage('count')
                }

                self:sendResponse({type="stats", stats = stats})
            elseif command.type == "evaluate" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The evaluate command runs an object through the network and
                -- return the result
                local batch = self:prepareInputBatch(command.samples)

                local results = self:evaluateBatch(batch)

                local convertedResults = {}
                for n = 1,#results do
                    local id = command.ids[n]
                    local result = results[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    type = "evaluationCompleted",
                    objects = convertedResults
                }

                self:sendResponse(response)

            elseif command.type == "evaluateBatch" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The evaluate command runs an object through the network and
                -- return the result
                local batchFile = torch.load(command.batchFilename)
                local batch = batchFile.data
                local results = self:evaluateBatch(batch)

                local convertedResults = {}
                for n = 1,#results do
                    local id = batchFile.ids[n]
                    local result = results[n]
                    local converted = self:convertOutputOut(result)
                    converted.id = id
                    table.insert(convertedResults, converted)
                end

                local response = {
                    type = "evaluationCompleted",
                    objects = convertedResults
                }
                self:sendResponse(response)
            elseif command.type == "save" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The save command causes the process to save the trained model out to disk
                self.moduleSaveCopy:getParameters():copy(self.params)
                torch.save("model.t7", self.moduleSaveCopy)
                local response = {type = "saved"}
                self:sendResponse(response)
            elseif command.type == "load" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The load command causes the process to load the trained model from the disk
                self.module = torch.load("model.t7")
                self.moduleSaveCopy = torch.load("model.t7")
                self.params, self.gradParams = self.module:getParameters()
                local response = {type = "loaded"}
                self:sendResponse(response)
            elseif command.type == "synchronize" then
                -- Initialize the model
                if not self.moduleInitialized then
                    self:createModule()
                end

                -- The synchronize command forces the process to synchronize its parameters with other processes
                self.allReduceSGD.synchronizeParameters({self.params})
                local response = {type = "synchronized"}
                self:sendResponse(response)
            end

        end
    until false == true -- Repeat forever. For some reason, the simple while True: doesn't actually work in Lua.
end

local script = TransformTrainingScript.new()

-- Override the print function
print = function(message)
    script:log(message)
end

script:enterTrainingLoop()
